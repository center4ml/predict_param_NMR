{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluates the YOLO model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ranges of parameters in units and constants used in experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_min, sp_max = -10., 10.\n",
    "fr_min, fr_max = 0., 256.\n",
    "dc_min, dc_max = 0.1, 10.\n",
    "am_min, am_max = 0.1, 5.\n",
    "\n",
    "series = 20\n",
    "dwmin, dwmax = -10., 10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of pixels and cells along the speed and frequency dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_pixels, fr_pixels = 256, 256\n",
    "sp_cells, fr_cells = 16, 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Offsets of cells relative to the entire grid in range from 0 to the number of cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr_offsets, sp_offsets = tf.meshgrid(tf.range(fr_cells, dtype = tf.float32),\n",
    "                                     tf.range(sp_cells, dtype = tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Takes a spectrum and returns objectness and peak shifts on the grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrum = tf.keras.Input([256, 256])\n",
    "signal = tf.keras.layers.Reshape([256, 256, 1])(spectrum)\n",
    "signal = tf.keras.layers.Conv2D(32, 3, 1, 'same', activation = 'relu')(signal)\n",
    "signal = tf.keras.layers.Conv2D(32, 3, 1, 'same', activation = 'relu')(signal)\n",
    "signal = tf.keras.layers.MaxPool2D()(signal) #(128, 128, 32)\n",
    "signal = tf.keras.layers.Conv2D(64, 3, 1, 'same', activation = 'relu')(signal)\n",
    "signal = tf.keras.layers.Conv2D(64, 3, 1, 'same', activation = 'relu')(signal)\n",
    "signal = tf.keras.layers.MaxPool2D()(signal) #(64, 64, 64)\n",
    "signal = tf.keras.layers.Conv2D(128, 3, 1, 'same', activation = 'relu')(signal)\n",
    "signal = tf.keras.layers.Conv2D(128, 3, 1, 'same', activation = 'relu')(signal)\n",
    "signal = tf.keras.layers.MaxPool2D()(signal) #(32, 32, 128)\n",
    "signal = tf.keras.layers.Conv2D(256, 3, 1, 'same', activation = 'relu')(signal)\n",
    "signal = tf.keras.layers.Conv2D(256, 3, 1, 'same', activation = 'relu')(signal)\n",
    "signal = tf.keras.layers.MaxPool2D()(signal) #(16, 16, 256)\n",
    "signal = tf.keras.layers.Conv2D(512, 3, 1, 'same', activation = 'relu')(signal)\n",
    "ob_logits = tf.keras.layers.Conv2D(1, 3, 1, 'same')(signal)\n",
    "ob_logits = tf.keras.layers.Reshape([16, 16])(ob_logits)\n",
    "sp_shifts = tf.keras.layers.Conv2D(1, 3, 1, 'same')(signal)\n",
    "sp_shifts = tf.keras.layers.Reshape([16, 16])(sp_shifts)\n",
    "fr_shifts = tf.keras.layers.Conv2D(1, 3, 1, 'same')(signal)\n",
    "fr_shifts = tf.keras.layers.Reshape([16, 16])(fr_shifts)\n",
    "dc_shifts = tf.keras.layers.Conv2D(1, 3, 1, 'same')(signal)\n",
    "dc_shifts = tf.keras.layers.Reshape([16, 16])(dc_shifts)\n",
    "am_shifts = tf.keras.layers.Conv2D(1, 3, 1, 'same')(signal)\n",
    "am_shifts = tf.keras.layers.Reshape([16, 16])(am_shifts)\n",
    "model = tf.keras.models.Model(spectrum, (ob_logits, sp_shifts, fr_shifts, dc_shifts, am_shifts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the model weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('model/05extract.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auxiliary arrays for generating spectrum in tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = tf.complex(tf.range(2 * fr_pixels, dtype = tf.float32) / fr_pixels / 2., 0.)\n",
    "a = tf.range(series, dtype = tf.float32)\n",
    "b = 2. * math.pi * \\\n",
    "    tf.complex(0., tf.range(dwmin, dwmax, (dwmax - dwmin) / sp_pixels, dtype = tf.float32))[:, None] * t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to take peak parameters and returns the resulting spectrum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def get(ob_labels, sp_values, fr_values, dc_values, am_values):\n",
    "    f = a[:, None, None] * sp_values + fr_values + fr_pixels / 2.\n",
    "    fid = tf.complex(ob_labels * am_values, 0.) * \\\n",
    "          tf.exp(2. * math.pi * t[:, None, None, None] * (tf.complex(-dc_values, f))) * \\\n",
    "          tf.cast(tf.logical_and(0.8 * fr_pixels / 2. <= f, f <= 2. * fr_pixels - 0.8 * fr_pixels / 2.), \n",
    "                  tf.complex64)\n",
    "    fid = tf.reduce_sum(fid, [2, 3])\n",
    "    fid = tf.concat([fid[: 1] / 2., fid[1:]], 0)\n",
    "    p = tf.exp(-b[:, :, None] * tf.complex(a, 0.)) * fid\n",
    "    return tf.math.real(tf.signal.fft(tf.reduce_sum(p, 2)))[:, fr_pixels // 2 : 2 * fr_pixels - fr_pixels // 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to draw random peak parameters and yield the resulting spectrum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate():\n",
    "    while True:\n",
    "        #Random number of peaks from 1 to 9\n",
    "        count = tf.random.uniform([], 1, 10, dtype = tf.int32)\n",
    "        #Random objectness labels as 1. or 0. if a cell contains a peak or not\n",
    "        ob_labels = tf.concat([tf.ones([count]), tf.zeros([sp_cells * fr_cells - count])], -1)\n",
    "        ob_labels = tf.random.shuffle(ob_labels)\n",
    "        ob_labels = tf.reshape(ob_labels, [sp_cells, fr_cells])\n",
    "        #Random peak parameters relative to each cell in range from 0 to 1\n",
    "        sp_shifts = tf.random.uniform([sp_cells, fr_cells])\n",
    "        fr_shifts = tf.random.uniform([sp_cells, fr_cells])\n",
    "        dc_shifts = tf.random.uniform([sp_cells, fr_cells])\n",
    "        am_shifts = tf.random.uniform([sp_cells, fr_cells])\n",
    "        #Peak parameters relative to the entire grid in range from 0 to 1\n",
    "        sp_units = (sp_offsets + sp_shifts) / sp_cells\n",
    "        fr_units = (fr_offsets + fr_shifts) / fr_cells\n",
    "        dc_units = dc_shifts\n",
    "        am_units = am_shifts\n",
    "        #Peak parameters in units used in experiment\n",
    "        sp_values = sp_units * (sp_max - sp_min) + sp_min\n",
    "        fr_values = fr_units * (fr_max - fr_min) + fr_min\n",
    "        dc_values = dc_units * (dc_max - dc_min) + dc_min\n",
    "        am_values = am_units * (am_max - am_min) + am_min\n",
    "        spectrum = get(ob_labels, sp_values, fr_values, dc_values, am_values)\n",
    "        yield spectrum, (ob_labels, sp_shifts, fr_shifts, dc_shifts, am_shifts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function of normalize spectra to zero mean and unit variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def normalize(spectrum, target):\n",
    "    spectrum = (spectrum - 180.45589) / 217.40448\n",
    "    return spectrum, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batched dataset of normalized spectra from function of generate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_generator(generate,\n",
    "                                         output_signature = (tf.TensorSpec([sp_pixels, fr_pixels]),\n",
    "                                                             (tf.TensorSpec([sp_cells, fr_cells]),\n",
    "                                                              tf.TensorSpec([sp_cells, fr_cells]),\n",
    "                                                              tf.TensorSpec([sp_cells, fr_cells]),\n",
    "                                                              tf.TensorSpec([sp_cells, fr_cells]),\n",
    "                                                              tf.TensorSpec([sp_cells, fr_cells]))))\n",
    "dataset = dataset.map(normalize).batch(16384)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generated spectra and true objectness labels and peak shifts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrum, (ob_labels0, sp_shifts0, fr_shifts0, dc_shifts0, am_shifts0) = next(iter(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicted objectness logits and peak shifts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ob_logits1, sp_shifts1, fr_shifts1, dc_shifts1, am_shifts1 = model.predict(spectrum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "True peak shifts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_shifts0 = sp_shifts0.numpy()\n",
    "fr_shifts0 = fr_shifts0.numpy()\n",
    "dc_shifts0 = dc_shifts0.numpy()\n",
    "am_shifts0 = am_shifts0.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "True peak units and predicted peak units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_units0 = (sp_offsets + sp_shifts0) / sp_cells\n",
    "fr_units0 = (fr_offsets + fr_shifts0) / fr_cells\n",
    "dc_units0 = dc_shifts0\n",
    "am_units0 = am_shifts0\n",
    "\n",
    "sp_units1 = (sp_offsets + sp_shifts1) / sp_cells\n",
    "fr_units1 = (fr_offsets + fr_shifts1) / fr_cells\n",
    "dc_units1 = dc_shifts1\n",
    "am_units1 = am_shifts1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "True objectness labels and predicted objectness labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ob_labels0 = ob_labels0.numpy()\n",
    "ob_labels0 = ob_labels0 > 0.5\n",
    "\n",
    "ob_labels1 = ob_logits1 > 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objectness accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ob_labels_acc: 0.9983272552490234\n"
     ]
    }
   ],
   "source": [
    "ob_labels_acc = np.mean(ob_labels1 == ob_labels0)\n",
    "print('ob_labels_acc:', ob_labels_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objectness labels for correctly predicted peaks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ob_labels = np.logical_and(ob_labels1, ob_labels0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "True shifts for correctly predicted peaks and predicted shifts for correctly predicted peaks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_shifts0 = sp_shifts0[ob_labels]\n",
    "fr_shifts0 = fr_shifts0[ob_labels]\n",
    "dc_shifts0 = dc_shifts0[ob_labels]\n",
    "am_shifts0 = am_shifts0[ob_labels]\n",
    "\n",
    "sp_shifts1 = sp_shifts1[ob_labels]\n",
    "fr_shifts1 = fr_shifts1[ob_labels]\n",
    "dc_shifts1 = dc_shifts1[ob_labels]\n",
    "am_shifts1 = am_shifts1[ob_labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Root-mean-squared errors of shifts for correctly predicted peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sp_shifts_rmse: 0.06918289\n",
      "fr_shifts_rmse: 0.057826433\n",
      "dc_shifts_rmse: 0.06674501\n",
      "am_shifts_rmse: 0.080794424\n"
     ]
    }
   ],
   "source": [
    "sp_shifts_rmse = np.sqrt(np.square(sp_shifts1 - sp_shifts0).mean())\n",
    "fr_shifts_rmse = np.sqrt(np.square(fr_shifts1 - fr_shifts0).mean())\n",
    "dc_shifts_rmse = np.sqrt(np.square(dc_shifts1 - dc_shifts0).mean())\n",
    "am_shifts_rmse = np.sqrt(np.square(am_shifts1 - am_shifts0).mean())\n",
    "\n",
    "print('sp_shifts_rmse:', sp_shifts_rmse)\n",
    "print('fr_shifts_rmse:', fr_shifts_rmse)\n",
    "print('dc_shifts_rmse:', dc_shifts_rmse)\n",
    "print('am_shifts_rmse:', am_shifts_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean errors of shifts for correctly predicted peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sp_shifts_me: -0.012151501\n",
      "fr_shifts_me: 0.018861089\n",
      "dc_shifts_me: -0.016786994\n",
      "am_shifts_me: -0.033531547\n"
     ]
    }
   ],
   "source": [
    "sp_shifts_me = np.mean(sp_shifts1 - sp_shifts0)\n",
    "fr_shifts_me = np.mean(fr_shifts1 - fr_shifts0)\n",
    "dc_shifts_me = np.mean(dc_shifts1 - dc_shifts0)\n",
    "am_shifts_me = np.mean(am_shifts1 - am_shifts0)\n",
    "\n",
    "print('sp_shifts_me:', sp_shifts_me)\n",
    "print('fr_shifts_me:', fr_shifts_me)\n",
    "print('dc_shifts_me:', dc_shifts_me)\n",
    "print('am_shifts_me:', am_shifts_me)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard deviations of errors in shifts for correctly predicted peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sp_shifts_estd: 0.06810736\n",
      "fr_shifts_estd: 0.054664027\n",
      "dc_shifts_estd: 0.06459949\n",
      "am_shifts_estd: 0.07350765\n"
     ]
    }
   ],
   "source": [
    "sp_shifts_estd = np.sqrt(np.square(sp_shifts1 - sp_shifts0 - sp_shifts_me).mean())\n",
    "fr_shifts_estd = np.sqrt(np.square(fr_shifts1 - fr_shifts0 - fr_shifts_me).mean())\n",
    "dc_shifts_estd = np.sqrt(np.square(dc_shifts1 - dc_shifts0 - dc_shifts_me).mean())\n",
    "am_shifts_estd = np.sqrt(np.square(am_shifts1 - am_shifts0 - am_shifts_me).mean())\n",
    "\n",
    "print('sp_shifts_estd:', sp_shifts_estd)\n",
    "print('fr_shifts_estd:', fr_shifts_estd)\n",
    "print('dc_shifts_estd:', dc_shifts_estd)\n",
    "print('am_shifts_estd:', am_shifts_estd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "True units for correctly predicted peaks and predicted units for correctly predicted peaks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_units0 = sp_units0[ob_labels]\n",
    "fr_units0 = fr_units0[ob_labels]\n",
    "dc_units0 = dc_units0[ob_labels]\n",
    "am_units0 = am_units0[ob_labels]\n",
    "\n",
    "sp_units1 = sp_units1[ob_labels]\n",
    "fr_units1 = fr_units1[ob_labels]\n",
    "dc_units1 = dc_units1[ob_labels]\n",
    "am_units1 = am_units1[ob_labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Root-mean-squared errors of units for correctly predicted peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sp_units_rmse: 0.0043239305\n",
      "fr_units_rmse: 0.0036141523\n",
      "dc_units_rmse: 0.06674501\n",
      "am_units_rmse: 0.080794424\n"
     ]
    }
   ],
   "source": [
    "sp_units_rmse = np.sqrt(np.square(sp_units1 - sp_units0).mean())\n",
    "fr_units_rmse = np.sqrt(np.square(fr_units1 - fr_units0).mean())\n",
    "dc_units_rmse = np.sqrt(np.square(dc_units1 - dc_units0).mean())\n",
    "am_units_rmse = np.sqrt(np.square(am_units1 - am_units0).mean())\n",
    "\n",
    "print('sp_units_rmse:', sp_units_rmse)\n",
    "print('fr_units_rmse:', fr_units_rmse)\n",
    "print('dc_units_rmse:', dc_units_rmse)\n",
    "print('am_units_rmse:', am_units_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean errors of units for correctly predicted peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sp_units_me: -0.00075946876\n",
      "fr_units_me: 0.001178818\n",
      "dc_units_me: -0.016786994\n",
      "am_units_me: -0.033531547\n"
     ]
    }
   ],
   "source": [
    "sp_units_me = np.mean(sp_units1 - sp_units0)\n",
    "fr_units_me = np.mean(fr_units1 - fr_units0)\n",
    "dc_units_me = np.mean(dc_units1 - dc_units0)\n",
    "am_units_me = np.mean(am_units1 - am_units0)\n",
    "\n",
    "print('sp_units_me:', sp_units_me)\n",
    "print('fr_units_me:', fr_units_me)\n",
    "print('dc_units_me:', dc_units_me)\n",
    "print('am_units_me:', am_units_me)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard deviations of errors in units for correctly predicted peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sp_units_estd: 0.0042567104\n",
      "fr_units_estd: 0.0034165017\n",
      "dc_units_estd: 0.06459949\n",
      "am_units_estd: 0.07350765\n"
     ]
    }
   ],
   "source": [
    "sp_units_estd = np.sqrt(np.square(sp_units1 - sp_units0 - sp_units_me).mean())\n",
    "fr_units_estd = np.sqrt(np.square(fr_units1 - fr_units0 - fr_units_me).mean())\n",
    "dc_units_estd = np.sqrt(np.square(dc_units1 - dc_units0 - dc_units_me).mean())\n",
    "am_units_estd = np.sqrt(np.square(am_units1 - am_units0 - am_units_me).mean())\n",
    "\n",
    "print('sp_units_estd:', sp_units_estd)\n",
    "print('fr_units_estd:', fr_units_estd)\n",
    "print('dc_units_estd:', dc_units_estd)\n",
    "print('am_units_estd:', am_units_estd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
